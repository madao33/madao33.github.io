

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/avatar/avatar.jpg">
  <link rel="icon" href="https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/avatar/avatar.jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="madao33">
  <meta name="keywords" content="">
  
    <meta name="description" content="ResNet学习笔记及仿真前言深度残差网络（Deep Residual Network）是cnn机器视觉史上的一件里程碑的事件，在2015年，ResNet在ImageNet和COCO数据集上获得了非常优秀的成绩。如下所示：  ImageNet Classification: “Ultra-deep”152-layer nets ImageNet Detection: 16% better than">
<meta property="og:type" content="article">
<meta property="og:title" content="ResNet学习笔记及代码实现">
<meta property="og:url" content="http://example.com/2021/08/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/ResNet%E7%BD%91%E7%BB%9C%E7%AE%80%E8%BF%B0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="ResNet学习笔记及仿真前言深度残差网络（Deep Residual Network）是cnn机器视觉史上的一件里程碑的事件，在2015年，ResNet在ImageNet和COCO数据集上获得了非常优秀的成绩。如下所示：  ImageNet Classification: “Ultra-deep”152-layer nets ImageNet Detection: 16% better than">
<meta property="og:locale">
<meta property="og:image" content="https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/resnet/fig2.png">
<meta property="article:published_time" content="2021-08-06T04:29:59.000Z">
<meta property="article:modified_time" content="2022-08-07T07:13:38.581Z">
<meta property="article:author" content="madao33">
<meta property="article:tag" content="ResNet">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="cnn">
<meta property="article:tag" content="python">
<meta property="article:tag" content="pytorch">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/resnet/fig2.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>ResNet学习笔记及代码实现 - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.2","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>madao33</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                主页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('https://madao33-static.oss-cn-hangzhou.aliyuncs.com/post_img/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="ResNet相关的一些介绍及代码复现"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2021-08-06 12:29" pubdate>
          August 6, 2021 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          29k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          244 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">ResNet相关的一些介绍及代码复现</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="ResNet学习笔记及仿真"><a href="#ResNet学习笔记及仿真" class="headerlink" title="ResNet学习笔记及仿真"></a>ResNet学习笔记及仿真</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>深度残差网络（Deep Residual Network）是cnn机器视觉史上的一件里程碑的事件，在2015年，ResNet在ImageNet和COCO数据集上获得了非常优秀的成绩。如下所示：</p>
<ul>
<li>ImageNet Classification: “Ultra-deep”<code>152-layer</code> nets</li>
<li>ImageNet Detection: <code>16%</code> better than 2nd</li>
<li>ImageNet Localization: <code>27%</code> better than 2nd</li>
<li>COCO Detection: <code>11%</code> better than 2nd</li>
<li>COCO Segmentation: <code>12%</code> better than 2nd</li>
</ul>
<p>ResNet获得了五项第一，再一次的刷新了CNN模型在ImageNet上的历史<a href="#ref-1"><sup>[1]</sup></a>，而论文的作者<a target="_blank" rel="noopener" href="http://kaiminghe.com/">何凯明</a>也获得了CVPR2016最佳论文奖<a href="#ref-2"><sup>[2]</sup></a>。以下是记录了解ResNet的一些笔记，主要是来自于15年和16年何凯明所在的微软研究院发表的论文。</p>
<h2 id="深度网络退化问题（degradation-problem-of-deep-network）"><a href="#深度网络退化问题（degradation-problem-of-deep-network）" class="headerlink" title="深度网络退化问题（degradation problem of deep network）"></a>深度网络退化问题（degradation problem of deep network）</h2><p>从<code>AlexNet</code>到<code>GoogLeNet</code>，看起来好像是网络越深越好，但是直接秉持着<code>We need go deeper</code>的思想构建神经网络，到最后会发现，随着网络越来越深，会出现<strong>梯度消失（vanishing gradients）</strong>和<strong>梯度爆炸（exploding gradients）</strong>以及<strong>网络退化（network degradation）</strong>：</p>
<ul>
<li><strong>梯度消失和爆炸（vanishing&#x2F;exploding gradients）</strong>：网络层数太深引发的梯度方向传播中的连乘效应引起</li>
<li><strong>网络退化（network degradation）</strong>：较深的模型可以看作是较浅模型的超空间，理论上较深的模型可以看作是较浅模型的恒等映射，但是实际上较深模型后面添加的不是恒等映射，而是一些非线性层<a href="#ref-3"><sup>[3]</sup></a></li>
</ul>
<p>对于梯度消失和爆炸的应对方法如下：</p>
<ul>
<li><strong>改换激活函数</strong>: 使用<code>relu</code>、<code>LeakyRelu</code>、<code>ELU</code>等激活函数可以改善梯度消散或爆炸问题。<code>relu</code>导数的正数部分恒等于1，所以不会产生梯度消失和梯度爆炸</li>
<li><strong>BatchNormalization</strong>: 对每一层的输入做scale和shift方法，将每层神经元的输入分布强行拉回均值为0、方差为1的标准正态分布，这就使得激活层输入值落入在非线性函数对输入值比较敏感的区域，使得输入的小变化会导致损失函数较大的变化，使得梯度变大，训练速度加快，且避免梯度消失问题</li>
<li><strong>梯度剪切</strong>: 该方法主要是针对梯度爆炸提出。其思想是设置一个梯度剪切阈值，更新梯度时，如果梯度超过这个阈值，那么限制其在这个范围之内</li>
</ul>
<p>但是随着网络的加深，可以看到的是训练误差和测试误差都开始增加，这自然不是过拟合引起的，而是网络出现退化<a href="#ref-4"><sup>[4]</sup></a>，如<a href="#fig-1">figure1</a>所示：</p>
<div id="fig-1"></div>

<img src="https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/resnet/fig1.png" srcset="/img/loading.gif" lazyload style="zoom: 80%;" />

<p>网络退化表明了并非所有系统都同样容易优化。考虑一个较深的网络和一个较浅的网络，更深的网络对应更浅的网络相当于是增加了更多的层，添加的层可以是恒等映射（identity mapping），而其他的层是相当于是更浅的模型中直接复制的，这种构造容易得到，较深的模型不会产生比较浅的模型更高的训练误差，但是实验表明，简单地加深网络模型会出现网络退化的问题。</p>
<h2 id="残差块（Residual-block）"><a href="#残差块（Residual-block）" class="headerlink" title="残差块（Residual block）"></a>残差块（Residual block）</h2><div id="fig-2"></div>

<p><img src="https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/resnet/fig2.png" srcset="/img/loading.gif" lazyload></p>
<p>网络退化出现的原因就是<strong>现有的网络无法实现恒等映射</strong>，将想要得到的恒等映射函数表示为 $H(x)&#x3D;x$，残差块网络设计为 $H(x)&#x3D;F(x)+x$，即直接将恒等映射作为网络的一部分，就可以将问题转化为学习一个残差函数 $F(x)&#x3D;H(x)-x$，那么只要 $F(x)&#x3D;0$，就可以构成一个恒等映射 $H(x)&#x3D;x$，拟合残差比拟合恒等映射容易的多<a href="#ref-5"><sup>[5]</sup></a>。从数学上更加详细地描述残差结构，可以是：</p>
<div id="eqn-1"></div>

<p>$$<br>y&#x3D;F(x, W_i)+x<br>$$</p>
<p>其中 $x$ 和 $y$ 表示的分别是所考虑的层的输入和输出向量，函数 $F(x, W_i)$ 表示要学习的残差映射，操作 $F(x, W_i)+x$ 是通过跳接实现，在<a href="#eqn-1">方程1</a>中 $x$ 和 $F$ 的维度必须相同，否则，需要对跳接进行线性投影 $W_s$ 来匹配维度：</p>
<div id="eqn-2"></div>

<p>$$<br>y&#x3D;F(x, W_i)+W_s x<br>$$</p>
<ul>
<li><p>$F(x)+x$ 的公式可以通过具有跳接（shortcut connections）的前馈神经网络来实现，跳接可以是跳过一层或者多层的连接，通过跳接在激活函数前，将上一层或几层的输出与本层输出相加，将求和结果输入到激活函数作为本层的输出，残差块示例如<a href="#fig-2">figure2</a>所示</p>
</li>
<li><p>跳接只是执行<strong>恒等映射</strong>，他们的输出被添加到堆叠层的输出中，这不会增加额外的参数，也不会增加计算复杂性</p>
</li>
<li><p>添加了残差网络，可以给神经网络一个多的选择，例如<strong>学习到的一层的参数是冗余的，那么就可以直接走跳接路线，跳过这个冗余层</strong>，而不用去拟合参数使得输出 $H(x)&#x3D;x$</p>
</li>
<li><p><strong>学习残差的计算量比学习输出等于输入小</strong>：例如普通网络为A，残差网络为B，输入为2，输出为2，那么普通网络就是$A(2)&#x3D;2$，而残差网络就是$B(2)&#x3D;F(2)+2&#x3D;2$，即残差网络中$F(2)&#x3D;0$。一般网络会将<strong>权重初始化为0附近的数</strong>，所以让$F(2)$拟合0会比$A(2)&#x3D;2$容易</p>
</li>
<li><p><strong>ReLU能够将负数激活为0</strong>，正数等于输出，这相当于过滤了负数的线性变化，让$F(x)&#x3D;0$变的更加容易</p>
<img src="https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/resnet/ReLU.png" srcset="/img/loading.gif" lazyload style="zoom:50%;" />
</li>
<li><p>对残差网络$H(x)&#x3D;F(x)+x$求梯度，即反向传播时，得到$H’(x)&#x3D;F’(x)+1$，<strong>残差结构的这个常数1能够保证求梯度的时候梯度不会消失</strong></p>
</li>
<li><p>这种结构不仅适用于全连接层，还<strong>适用于卷积层，逐通道地对两个特征图执行元素相加</strong></p>
</li>
</ul>
<h2 id="网络架构"><a href="#网络架构" class="headerlink" title="网络架构"></a>网络架构</h2><div id="fig3"></div>

<p><img src="https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/resnet/fig3.png" srcset="/img/loading.gif" lazyload></p>
<p>网络结构如<a href="#fig3">figure3</a>所示，从左到右分别是VGG-19（196亿次浮点运算）、34层不带残差的plain net（36亿次浮点运算）、34层的残差网络（36亿次浮点运算）</p>
<h4 id="plain-network"><a href="#plain-network" class="headerlink" title="plain network"></a>plain network</h4><ul>
<li>主要受到VGGNet的启发，遵循两个简单设计规则：<ul>
<li>对于相同的输出特征图大小，层具有相同数量的滤波器</li>
<li>如果特征图大小减半，则过滤器的数量加倍</li>
</ul>
</li>
<li>步长为2的卷积层直接执行下采样</li>
<li>网络结尾是一个整体平均池化层和一个1000路的全连接层和softmax函数</li>
<li>总体的带权重的层是34层</li>
<li>该模型比VGGNet相比具有更少的滤波器和更低的复杂度，plain net 有36亿次浮点运算，而VGG-19有196亿次浮点运算，前者是后者的18%</li>
</ul>
<h4 id="Residual-Network"><a href="#Residual-Network" class="headerlink" title="Residual Network"></a>Residual Network</h4><ul>
<li>在plain net网络中引入了<strong>跳接（shortcut conncetions）</strong>，将其转换为了对应的残差版本</li>
<li>跳接引入有两种形式：<ul>
<li>实线：跳接引入的输入和输出维度相同，可以直接相加，如<a href="#eqn-1">公式1</a></li>
<li>虚线：引入的维度增加时，可以有两种方式<ul>
<li>跳接仍然执行恒等映射，<strong>填充零</strong>元素保证维度相同</li>
<li>利用<a href="#eqn-2">公式2</a>对跳接进行<strong>投影</strong>来匹配维度</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h2><ul>
<li>遵循AlexNet数据预处理的方法，对图像进行裁剪和水平翻转得到224 x 224的图像，然后减去每个像素的平均值<a href="#ref-6"><sup>[6]</sup></a></li>
<li>每次卷积之后和激活函数之前采用批处理标准化（batch normalization, BN）</li>
<li>批大小（mini-batch ）为256</li>
<li>学习率（learning rate） 从 0.1 开始，当误差平稳时，学习率除以10，模型训练了 $60 \times 10^4$ 次迭代</li>
<li>权重衰减（weight decay）0.0001，动量（momentum）为 0.9</li>
<li>网络中没有使用到dropout</li>
</ul>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><h3 id="ImageNet分类结果"><a href="#ImageNet分类结果" class="headerlink" title="ImageNet分类结果"></a>ImageNet分类结果</h3><p>对比了18层和34层的plain net以及对应的ResNet，可以看到如<a href="#fig-4">figure4</a>所示，<strong>残差结果确实解决了退化问题</strong></p>
<div id="fig-4"></div>

<p><img src="https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/resnet/fig4.png" srcset="/img/loading.gif" lazyload></p>
<p>对比了ImageNet数据集的测试结果汇总如<a href="#table-3">表3</a>所示</p>
<div id="table-3"></div>

<img src=" https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/resnet/table3.png" srcset="/img/loading.gif" lazyload style="zoom:80%;" />

<h2 id="基于cifar10数据集的ResNet实现-7"><a href="#基于cifar10数据集的ResNet实现-7" class="headerlink" title="基于cifar10数据集的ResNet实现[7]"></a>基于cifar10数据集的ResNet实现<a href="#ref-7"><sup>[7]</sup></a></h2><h3 id="导入基本模块"><a href="#导入基本模块" class="headerlink" title="导入基本模块"></a>导入基本模块</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> print_function<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">import</span> torchvision.transforms <span class="hljs-keyword">as</span> transforms<br></code></pre></td></tr></table></figure>

<h3 id="torchvision下载cifar10数据集"><a href="#torchvision下载cifar10数据集" class="headerlink" title="torchvision下载cifar10数据集"></a>torchvision下载cifar10数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">transform = transforms.Compose([<br>    transforms.RandomHorizontalFlip(),<br>    transforms.ToTensor(),<br>    transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>)),<br>])<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">train_set = torchvision.datasets.CIFAR10(<span class="hljs-string">&#x27;../data&#x27;</span>, train=<span class="hljs-literal">True</span>, <br>                                         download=<span class="hljs-literal">True</span>, transform=transform)<br>test_set = torchvision.datasets.CIFAR10(<span class="hljs-string">&#x27;../data&#x27;</span>, train=<span class="hljs-literal">False</span>, <br>                                        download=<span class="hljs-literal">True</span>, transform=transform)<br>train_loader = torch.utils.data.DataLoader(train_set, batch_size=<span class="hljs-number">128</span>, <br>                                           shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">4</span>)<br>test_loader = torch.utils.data.DataLoader(test_set, batch_size=<span class="hljs-number">100</span>, <br>                                          shuffle=<span class="hljs-literal">False</span>, num_workers=<span class="hljs-number">4</span>)<br>classes = (<span class="hljs-string">&#x27;plane&#x27;</span>, <span class="hljs-string">&#x27;car&#x27;</span>, <span class="hljs-string">&#x27;bird&#x27;</span>, <span class="hljs-string">&#x27;cat&#x27;</span>, <span class="hljs-string">&#x27;deer&#x27;</span>,<br>           <span class="hljs-string">&#x27;dog&#x27;</span>, <span class="hljs-string">&#x27;frog&#x27;</span>, <span class="hljs-string">&#x27;horse&#x27;</span>, <span class="hljs-string">&#x27;ship&#x27;</span>, <span class="hljs-string">&#x27;truck&#x27;</span>)<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">Using downloaded and verified file: ../data\cifar-10-python.tar.gz
Extracting ../data\cifar-10-python.tar.gz to ../data
Files already downloaded and verified
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">imshow</span>(<span class="hljs-params">img</span>):<br>    img = img / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span><br>    plt.imshow(np.transpose(img.numpy(), (<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>)))<br>    plt.show()<br>image_iter = <span class="hljs-built_in">iter</span>(train_loader)<br>images, _ = image_iter.<span class="hljs-built_in">next</span>()<br>imshow(torchvision.utils.make_grid(images[:<span class="hljs-number">4</span>]))<br></code></pre></td></tr></table></figure>


<p><img src="https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/resnet/ResNet_4_0.png" srcset="/img/loading.gif" lazyload alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">device = <span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span><br>device<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">&#39;cuda&#39;
</code></pre>
<h3 id="BasicBlock"><a href="#BasicBlock" class="headerlink" title="BasicBlock"></a>BasicBlock</h3><p><img src="https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/resnet/fig2.png" srcset="/img/loading.gif" lazyload alt="image.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">BasicBlock</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    对于浅层网络，我们使用基本的Block</span><br><span class="hljs-string">    基础块没有维度压缩，所以expansion=1</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    expansion = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels, out_channels, stride=<span class="hljs-number">1</span></span>):<br>        <span class="hljs-built_in">super</span>(BasicBlock, self).__init__()<br>        self.features = nn.Sequential(<br>            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="hljs-number">3</span>, stride=stride, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(out_channels),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Conv2d(out_channels, out_channels, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(out_channels)<br>        )<br><br>        <span class="hljs-comment"># 如果输入输出维度不等，则使用1x1卷积层来改变维度</span><br>        self.shortcut = nn.Sequential()<br>        <span class="hljs-keyword">if</span> stride != <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> in_channels != self.expansion * out_channels:<br>            self.shortcut = nn.Sequential(<br>                nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size=<span class="hljs-number">1</span>, stride=stride, bias=<span class="hljs-literal">False</span>),<br>                nn.BatchNorm2d(self.expansion * out_channels),<br>            )<br><br>            <br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        out = self.features(x)<br>        out += self.shortcut(x)<br>        out = torch.relu(out)<br>        <span class="hljs-keyword">return</span> out<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 测试</span><br>basic_block = BasicBlock(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>)<br><span class="hljs-built_in">print</span>(basic_block)<br>x = torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">64</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>)<br>y = basic_block(x)<br><span class="hljs-built_in">print</span>(y.shape)<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">BasicBlock(
  (features): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (shortcut): Sequential(
    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
torch.Size([2, 128, 32, 32])
</code></pre>
<h3 id="Bottleneck-Block"><a href="#Bottleneck-Block" class="headerlink" title="Bottleneck Block"></a>Bottleneck Block</h3><p><img src="https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/resnet/fig5.png" srcset="/img/loading.gif" lazyload alt="image.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Bottleneck</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    对于深层网络，我们使用BottleNeck，论文中提出其拥有近似的计算复杂度，但能节省很多资源</span><br><span class="hljs-string">    zip_channels: 压缩后的维数，最后输出的维数是 expansion * zip_channels</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    expansion = <span class="hljs-number">4</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels, zip_channels, stride=<span class="hljs-number">1</span></span>):<br>        <span class="hljs-built_in">super</span>(Bottleneck, self).__init__()<br>        out_channels = self.expansion * zip_channels<br>        self.features = nn.Sequential(<br>            nn.Conv2d(in_channels, zip_channels, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(zip_channels),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Conv2d(zip_channels, zip_channels, kernel_size=<span class="hljs-number">3</span>, stride=stride, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(zip_channels),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Conv2d(zip_channels, out_channels, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(out_channels)<br>        )<br>        self.shortcut = nn.Sequential()<br>        <span class="hljs-keyword">if</span> stride != <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> in_channels != out_channels:<br>            self.shortcut = nn.Sequential(<br>                nn.Conv2d(in_channels, out_channels, kernel_size=<span class="hljs-number">1</span>, stride=stride, bias=<span class="hljs-literal">False</span>),<br>                nn.BatchNorm2d(out_channels)<br>            )<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        out = self.features(x)<br>        out += self.shortcut(x)<br>        out = torch.relu(out)<br>        <span class="hljs-keyword">return</span> out<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 测试</span><br>bottleneck = Bottleneck(<span class="hljs-number">256</span>, <span class="hljs-number">128</span>)<br><span class="hljs-built_in">print</span>(bottleneck)<br>x = torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">256</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>)<br>y = bottleneck(x)<br><span class="hljs-built_in">print</span>(y.shape)<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">Bottleneck(
  (features): Sequential(
    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (shortcut): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
)
torch.Size([2, 512, 32, 32])
</code></pre>
<h3 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h3><p><img src="https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/resnet/fig3.png" srcset="/img/loading.gif" lazyload alt="image.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ResNet</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    不同的ResNet架构都是统一的一层特征提取、四层残差，不同点在于每层残差的深度。</span><br><span class="hljs-string">    对于cifar10，feature map size的变化如下：</span><br><span class="hljs-string">    (32, 32, 3) -&gt; [Conv2d] -&gt; (32, 32, 64) -&gt; [Res1] -&gt; (32, 32, 64) -&gt; [Res2] </span><br><span class="hljs-string"> -&gt; (16, 16, 128) -&gt; [Res3] -&gt; (8, 8, 256) -&gt;[Res4] -&gt; (4, 4, 512) -&gt; [AvgPool] </span><br><span class="hljs-string"> -&gt; (1, 1, 512) -&gt; [Reshape] -&gt; (512) -&gt; [Linear] -&gt; (10)</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, block, num_blocks, num_classes=<span class="hljs-number">10</span></span>):<br>        <span class="hljs-built_in">super</span>(ResNet, self).__init__()<br>        self.in_channels = <span class="hljs-number">64</span><br>        self.features = nn.Sequential(<br>            nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(<span class="hljs-number">64</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br>        )<br><br>        self.layer1 = self._make_layer(block, <span class="hljs-number">64</span>, num_blocks[<span class="hljs-number">0</span>], stride=<span class="hljs-number">1</span>)<br>        self.layer2 = self._make_layer(block, <span class="hljs-number">128</span>, num_blocks[<span class="hljs-number">1</span>], stride=<span class="hljs-number">2</span>)<br>        self.layer3 = self._make_layer(block, <span class="hljs-number">256</span>, num_blocks[<span class="hljs-number">2</span>], stride=<span class="hljs-number">2</span>)<br>        self.layer4 = self._make_layer(block, <span class="hljs-number">512</span>, num_blocks[<span class="hljs-number">3</span>], stride=<span class="hljs-number">2</span>)<br><br>        <span class="hljs-comment"># cifar10经过上述结构后，到这里的feature map size是 4 x 4 x 512 x expansion</span><br>        <span class="hljs-comment"># 所以这里用了 4 x 4 的平均池化</span><br>        self.avg_pool = nn.AvgPool2d(kernel_size=<span class="hljs-number">4</span>)<br>        self.classifer = nn.Linear(<span class="hljs-number">512</span> * block.expansion, num_classes)<br><br>        <br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_make_layer</span>(<span class="hljs-params">self, block, out_channels, num_blocks, stride</span>):<br>        <span class="hljs-comment"># 第一个block要进行降采样</span><br>        strides = [stride] + [<span class="hljs-number">1</span>] * (num_blocks - <span class="hljs-number">1</span>)<br>        layers = []<br>        <span class="hljs-keyword">for</span> stride <span class="hljs-keyword">in</span> strides:<br>            layers.append(block(self.in_channels, out_channels, stride))<br>            <span class="hljs-comment"># 如果是Bottleneck Block的话需要对每层输入的维度进行压缩，压缩后再增加维数</span><br>            <span class="hljs-comment"># 所以每层的输入维数也要跟着变</span><br>            self.in_channels = out_channels * block.expansion<br>        <span class="hljs-keyword">return</span> nn.Sequential(*layers)<br><br>    <br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        out = self.features(x)<br>        out = self.layer1(out)<br>        out = self.layer2(out)<br>        out = self.layer3(out)<br>        out = self.layer4(out)<br>        out = self.avg_pool(out)<br>        out = out.view(out.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)<br>        out = self.classifer(out)<br>        <span class="hljs-keyword">return</span> out<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">ResNet18</span>():<br>    <span class="hljs-keyword">return</span> ResNet(BasicBlock, [<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>])<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ResNet34</span>():<br>    <span class="hljs-keyword">return</span> ResNet(BasicBlock, [<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">3</span>])<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ResNet50</span>():<br>    <span class="hljs-keyword">return</span> ResNet(Bottleneck, [<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">3</span>])<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ResNet101</span>():<br>    <span class="hljs-keyword">return</span> ResNet(Bottleneck, [<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">23</span>,<span class="hljs-number">3</span>])<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ResNet152</span>():<br>    <span class="hljs-keyword">return</span> ResNet(Bottleneck, [<span class="hljs-number">3</span>,<span class="hljs-number">8</span>,<span class="hljs-number">36</span>,<span class="hljs-number">3</span>])<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">net = ResNet34().to(device)<br><span class="hljs-built_in">print</span>(net)<br><span class="hljs-keyword">if</span> device == <span class="hljs-string">&#x27;cuda&#x27;</span>:<br>    net = nn.DataParallel(net)<br>    <span class="hljs-comment"># 当计算图不会改变的时候（每次输入形状相同，模型不改变）的情况下可以提高性能，反之则降低性能</span><br>    torch.backends.cudnn.benchmark = <span class="hljs-literal">True</span><br></code></pre></td></tr></table></figure>

<pre><code class="hljs">ResNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (layer1): Sequential(
    (0): BasicBlock(
      (features): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (features): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Sequential()
    )
    (2): BasicBlock(
      (features): Sequential(
        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (features): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (features): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Sequential()
    )
    (2): BasicBlock(
      (features): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Sequential()
    )
    (3): BasicBlock(
      (features): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (features): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (features): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Sequential()
    )
    (2): BasicBlock(
      (features): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Sequential()
    )
    (3): BasicBlock(
      (features): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Sequential()
    )
    (4): BasicBlock(
      (features): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Sequential()
    )
    (5): BasicBlock(
      (features): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (features): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (features): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Sequential()
    )
    (2): BasicBlock(
      (features): Sequential(
        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (shortcut): Sequential()
    )
  )
  (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)
  (classifer): Linear(in_features=512, out_features=10, bias=True)
)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 测试</span><br>x = torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>).to(device)<br>y = net(x)<br><span class="hljs-built_in">print</span>(y.shape)<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">torch.Size([2, 10])
</code></pre>
<h3 id="train-model"><a href="#train-model" class="headerlink" title="train model"></a>train model</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">lr = <span class="hljs-number">1e-1</span><br>momentum = <span class="hljs-number">0.9</span><br>weight_decay = <span class="hljs-number">5e-4</span><br>criterion = nn.CrossEntropyLoss()<br>optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)<br>scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, threshold=<span class="hljs-number">0.1</span>, patience=<span class="hljs-number">3</span>, verbose=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Training</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">epoch</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;\nEpoch: %d&#x27;</span> % (epoch))<br>    net.train()<br>    train_loss = <span class="hljs-number">0</span><br>    correct = <span class="hljs-number">0</span><br>    total = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> batch_idx, (inputs, targets) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader):<br>        inputs, targets = inputs.to(device), targets.to(device)<br>        optimizer.zero_grad()<br>        outputs = net(inputs)<br>        loss = criterion(outputs, targets)<br>        loss.backward()<br>        optimizer.step()<br>        train_loss += loss.item()<br>        _, predicted = outputs.<span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>)<br>        total += targets.size(<span class="hljs-number">0</span>)<br>        correct += predicted.eq(targets).<span class="hljs-built_in">sum</span>().item()<br>        <span class="hljs-keyword">if</span> batch_idx % <span class="hljs-number">100</span> == <span class="hljs-number">99</span>:    <span class="hljs-comment"># print every 100 mini-batches</span><br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;[%d, %5d] loss: %.6f |  Acc: %.3f%% (%d/%d)&#x27;</span> %<br>                  (epoch + <span class="hljs-number">1</span>, batch_idx + <span class="hljs-number">1</span>, train_loss, <span class="hljs-number">100.</span>*correct/total, correct, total))<br>    <span class="hljs-keyword">return</span> train_loss<br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">load_model = <span class="hljs-literal">False</span><br><span class="hljs-keyword">if</span> load_model:<br>    checkpoint = torch.load(<span class="hljs-string">&#x27;./checkpoint/res18.ckpt&#x27;</span>)<br>    net.load_state_dict(checkpoint[<span class="hljs-string">&#x27;net&#x27;</span>])<br>    start_epoch = checkpoint[<span class="hljs-string">&#x27;epoch&#x27;</span>]<br><span class="hljs-keyword">else</span>:<br>    start_epoch = <span class="hljs-number">0</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;start_epoch: %s&#x27;</span> % start_epoch)<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">start_epoch: 0
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(start_epoch, <span class="hljs-number">50</span>):<br>    loss = train(epoch)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Total loss: %.6f&#x27;</span> % loss)<br>    start_epoch = epoch<br>    scheduler.step(loss)<br></code></pre></td></tr></table></figure>


<pre><code class="hljs">Epoch: 0
[1,   100] loss: 118.672118 |  Acc: 56.953% (7290/12800)
[1,   200] loss: 235.403772 |  Acc: 57.355% (14683/25600)
[1,   300] loss: 342.972803 |  Acc: 58.721% (22549/38400)
Total loss: 436.702453

Epoch: 1
[2,   100] loss: 95.490529 |  Acc: 65.930% (8439/12800)
[2,   200] loss: 189.245391 |  Acc: 66.246% (16959/25600)
[2,   300] loss: 279.333860 |  Acc: 66.758% (25635/38400)
Total loss: 357.071455

Epoch: 2
[3,   100] loss: 76.589579 |  Acc: 73.203% (9370/12800)
[3,   200] loss: 151.513288 |  Acc: 73.492% (18814/25600)
[3,   300] loss: 224.068864 |  Acc: 73.836% (28353/38400)
Total loss: 286.139592

Epoch: 3
[4,   100] loss: 62.455524 |  Acc: 78.664% (10069/12800)
[4,   200] loss: 125.946750 |  Acc: 78.246% (20031/25600)
[4,   300] loss: 186.423765 |  Acc: 78.414% (30111/38400)
Total loss: 240.281207

Epoch: 4
[5,   100] loss: 54.547970 |  Acc: 81.414% (10421/12800)
[5,   200] loss: 110.654127 |  Acc: 80.898% (20710/25600)
[5,   300] loss: 166.249208 |  Acc: 80.919% (31073/38400)
Total loss: 215.950420

Epoch: 5
[6,   100] loss: 48.104260 |  Acc: 83.109% (10638/12800)
[6,   200] loss: 99.401246 |  Acc: 82.734% (21180/25600)
[6,   300] loss: 148.791911 |  Acc: 82.807% (31798/38400)
Total loss: 194.453984

Epoch: 6
[7,   100] loss: 44.256123 |  Acc: 85.352% (10925/12800)
[7,   200] loss: 90.796863 |  Acc: 84.582% (21653/25600)
[7,   300] loss: 138.052944 |  Acc: 84.396% (32408/38400)
Total loss: 181.198413

Epoch: 7
[8,   100] loss: 40.750996 |  Acc: 85.906% (10996/12800)
[8,   200] loss: 84.440442 |  Acc: 85.539% (21898/25600)
[8,   300] loss: 127.751372 |  Acc: 85.430% (32805/38400)
Total loss: 168.756287

Epoch: 8
[9,   100] loss: 40.119882 |  Acc: 86.266% (11042/12800)
[9,   200] loss: 79.863018 |  Acc: 86.211% (22070/25600)
[9,   300] loss: 120.620995 |  Acc: 86.188% (33096/38400)
Total loss: 158.876436

Epoch: 9
[10,   100] loss: 35.623312 |  Acc: 87.477% (11197/12800)
[10,   200] loss: 75.740778 |  Acc: 86.777% (22215/25600)
[10,   300] loss: 115.162053 |  Acc: 86.703% (33294/38400)
Total loss: 151.007361

Epoch: 10
[11,   100] loss: 34.881428 |  Acc: 88.039% (11269/12800)
[11,   200] loss: 71.926582 |  Acc: 87.699% (22451/25600)
[11,   300] loss: 109.965547 |  Acc: 87.375% (33552/38400)
Total loss: 145.488317

Epoch: 11
[12,   100] loss: 32.708189 |  Acc: 88.977% (11389/12800)
[12,   200] loss: 66.790455 |  Acc: 88.594% (22680/25600)
[12,   300] loss: 103.832237 |  Acc: 88.125% (33840/38400)
Total loss: 137.913376

Epoch: 12
[13,   100] loss: 31.950675 |  Acc: 89.242% (11423/12800)
[13,   200] loss: 65.730325 |  Acc: 88.820% (22738/25600)
[13,   300] loss: 101.885522 |  Acc: 88.430% (33957/38400)
Total loss: 135.173613

Epoch: 13
[14,   100] loss: 29.611200 |  Acc: 89.805% (11495/12800)
[14,   200] loss: 62.823584 |  Acc: 89.129% (22817/25600)
[14,   300] loss: 97.116191 |  Acc: 88.849% (34118/38400)
Total loss: 129.670478

Epoch: 14
[15,   100] loss: 29.925015 |  Acc: 89.875% (11504/12800)
[15,   200] loss: 62.226747 |  Acc: 89.516% (22916/25600)
[15,   300] loss: 95.177161 |  Acc: 89.206% (34255/38400)
Total loss: 126.196716

Epoch: 15
[16,   100] loss: 28.724815 |  Acc: 90.039% (11525/12800)
[16,   200] loss: 60.983424 |  Acc: 89.551% (22925/25600)
[16,   300] loss: 93.304751 |  Acc: 89.354% (34312/38400)
Total loss: 123.906554

Epoch: 16
[17,   100] loss: 27.764434 |  Acc: 90.305% (11559/12800)
[17,   200] loss: 57.115116 |  Acc: 90.148% (23078/25600)
[17,   300] loss: 89.535789 |  Acc: 89.685% (34439/38400)
Total loss: 118.733271

Epoch: 17
[18,   100] loss: 26.901688 |  Acc: 90.781% (11620/12800)
[18,   200] loss: 56.244663 |  Acc: 90.316% (23121/25600)
[18,   300] loss: 87.834935 |  Acc: 89.872% (34511/38400)
Total loss: 116.597480

Epoch: 18
[19,   100] loss: 27.289408 |  Acc: 90.633% (11601/12800)
[19,   200] loss: 57.436502 |  Acc: 90.137% (23075/25600)
[19,   300] loss: 88.500381 |  Acc: 89.846% (34501/38400)
Total loss: 115.314192

Epoch: 19
[20,   100] loss: 24.068543 |  Acc: 91.852% (11757/12800)
[20,   200] loss: 53.208921 |  Acc: 90.828% (23252/25600)
[20,   300] loss: 84.727040 |  Acc: 90.203% (34638/38400)
Total loss: 112.072869
Epoch    21: reducing learning rate of group 0 to 1.0000e-02.

Epoch: 20
[21,   100] loss: 17.140250 |  Acc: 94.570% (12105/12800)
[21,   200] loss: 30.638147 |  Acc: 95.156% (24360/25600)
[21,   300] loss: 41.904663 |  Acc: 95.573% (36700/38400)
Total loss: 51.213734

Epoch: 21
[22,   100] loss: 7.424102 |  Acc: 97.984% (12542/12800)
[22,   200] loss: 14.609958 |  Acc: 97.918% (25067/25600)
[22,   300] loss: 21.400117 |  Acc: 97.964% (37618/38400)
Total loss: 27.305064

Epoch: 22
[23,   100] loss: 5.123270 |  Acc: 98.586% (12619/12800)
[23,   200] loss: 9.734514 |  Acc: 98.684% (25263/25600)
[23,   300] loss: 14.615595 |  Acc: 98.648% (37881/38400)
Total loss: 19.189702

Epoch: 23
[24,   100] loss: 3.460799 |  Acc: 99.172% (12694/12800)
[24,   200] loss: 6.807557 |  Acc: 99.203% (25396/25600)
[24,   300] loss: 10.049018 |  Acc: 99.211% (38097/38400)
Total loss: 13.315432

Epoch: 24
[25,   100] loss: 2.478284 |  Acc: 99.469% (12732/12800)
[25,   200] loss: 4.640014 |  Acc: 99.492% (25470/25600)
[25,   300] loss: 6.763096 |  Acc: 99.505% (38210/38400)
Total loss: 9.023635

Epoch: 25
[26,   100] loss: 1.528404 |  Acc: 99.680% (12759/12800)
[26,   200] loss: 2.968595 |  Acc: 99.711% (25526/25600)
[26,   300] loss: 4.535004 |  Acc: 99.706% (38287/38400)
Total loss: 5.932488

Epoch: 26
[27,   100] loss: 1.165903 |  Acc: 99.852% (12781/12800)
[27,   200] loss: 2.107836 |  Acc: 99.867% (25566/25600)
[27,   300] loss: 3.091869 |  Acc: 99.875% (38352/38400)
Total loss: 4.153865

Epoch: 27
[28,   100] loss: 0.732892 |  Acc: 99.945% (12793/12800)
[28,   200] loss: 1.651403 |  Acc: 99.883% (25570/25600)
[28,   300] loss: 2.452116 |  Acc: 99.888% (38357/38400)
Total loss: 3.153302

Epoch: 28
[29,   100] loss: 0.618112 |  Acc: 99.945% (12793/12800)
[29,   200] loss: 1.297444 |  Acc: 99.941% (25585/25600)
[29,   300] loss: 1.891233 |  Acc: 99.943% (38378/38400)
Total loss: 2.471666

Epoch: 29
[30,   100] loss: 0.548403 |  Acc: 99.945% (12793/12800)
[30,   200] loss: 1.019150 |  Acc: 99.953% (25588/25600)
[30,   300] loss: 1.501457 |  Acc: 99.958% (38384/38400)
Total loss: 1.972135

Epoch: 30
[31,   100] loss: 0.435647 |  Acc: 99.969% (12796/12800)
[31,   200] loss: 0.805838 |  Acc: 99.977% (25594/25600)
[31,   300] loss: 1.260185 |  Acc: 99.971% (38389/38400)
Total loss: 1.586358

Epoch: 31
[32,   100] loss: 0.347193 |  Acc: 99.992% (12799/12800)
[32,   200] loss: 0.633916 |  Acc: 99.992% (25598/25600)
[32,   300] loss: 0.942637 |  Acc: 99.995% (38398/38400)
Total loss: 1.342172

Epoch: 32
[33,   100] loss: 0.301421 |  Acc: 99.984% (12798/12800)
[33,   200] loss: 0.628001 |  Acc: 99.980% (25595/25600)
[33,   300] loss: 0.972346 |  Acc: 99.982% (38393/38400)
Total loss: 1.273002

Epoch: 33
[34,   100] loss: 0.271426 |  Acc: 100.000% (12800/12800)
[34,   200] loss: 0.522611 |  Acc: 100.000% (25600/25600)
[34,   300] loss: 0.791412 |  Acc: 99.997% (38399/38400)
Total loss: 1.069014

Epoch: 34
[35,   100] loss: 0.272007 |  Acc: 100.000% (12800/12800)
[35,   200] loss: 0.500229 |  Acc: 100.000% (25600/25600)
[35,   300] loss: 0.741914 |  Acc: 99.997% (38399/38400)
Total loss: 0.962418

Epoch: 35
[36,   100] loss: 0.200861 |  Acc: 100.000% (12800/12800)
[36,   200] loss: 0.421179 |  Acc: 100.000% (25600/25600)
[36,   300] loss: 0.637626 |  Acc: 100.000% (38400/38400)
Total loss: 0.835531

Epoch: 36
[37,   100] loss: 0.200766 |  Acc: 100.000% (12800/12800)
[37,   200] loss: 0.397603 |  Acc: 100.000% (25600/25600)
[37,   300] loss: 0.606028 |  Acc: 99.995% (38398/38400)
Total loss: 0.800073

Epoch: 37
[38,   100] loss: 0.178643 |  Acc: 100.000% (12800/12800)
[38,   200] loss: 0.374064 |  Acc: 100.000% (25600/25600)
[38,   300] loss: 0.577130 |  Acc: 100.000% (38400/38400)
Total loss: 0.768444

Epoch: 38
[39,   100] loss: 0.192881 |  Acc: 100.000% (12800/12800)
[39,   200] loss: 0.412415 |  Acc: 99.996% (25599/25600)
[39,   300] loss: 0.607835 |  Acc: 99.997% (38399/38400)
Total loss: 0.769075

Epoch: 39
[40,   100] loss: 0.174156 |  Acc: 100.000% (12800/12800)
[40,   200] loss: 0.356172 |  Acc: 100.000% (25600/25600)
[40,   300] loss: 0.544260 |  Acc: 100.000% (38400/38400)
Total loss: 0.711841

Epoch: 40
[41,   100] loss: 0.197980 |  Acc: 99.992% (12799/12800)
[41,   200] loss: 0.405721 |  Acc: 99.996% (25599/25600)
[41,   300] loss: 0.596260 |  Acc: 99.997% (38399/38400)
Total loss: 0.783890

Epoch: 41
[42,   100] loss: 0.195553 |  Acc: 99.992% (12799/12800)
[42,   200] loss: 0.377932 |  Acc: 99.996% (25599/25600)
[42,   300] loss: 0.565132 |  Acc: 99.997% (38399/38400)
Total loss: 0.740863

Epoch: 42
[43,   100] loss: 0.184922 |  Acc: 100.000% (12800/12800)
[43,   200] loss: 0.370228 |  Acc: 99.996% (25599/25600)
[43,   300] loss: 0.563876 |  Acc: 99.997% (38399/38400)
Total loss: 0.738950

Epoch: 43
[44,   100] loss: 0.188086 |  Acc: 100.000% (12800/12800)
[44,   200] loss: 0.363090 |  Acc: 100.000% (25600/25600)
[44,   300] loss: 0.529876 |  Acc: 100.000% (38400/38400)
Total loss: 0.684271
Epoch    45: reducing learning rate of group 0 to 1.0000e-03.

Epoch: 44
[45,   100] loss: 0.180676 |  Acc: 99.992% (12799/12800)
[45,   200] loss: 0.349191 |  Acc: 99.996% (25599/25600)
[45,   300] loss: 0.512983 |  Acc: 99.997% (38399/38400)
Total loss: 0.664923

Epoch: 45
[46,   100] loss: 0.166781 |  Acc: 100.000% (12800/12800)
[46,   200] loss: 0.320780 |  Acc: 100.000% (25600/25600)
[46,   300] loss: 0.477024 |  Acc: 100.000% (38400/38400)
Total loss: 0.632136

Epoch: 46
[47,   100] loss: 0.153178 |  Acc: 100.000% (12800/12800)
[47,   200] loss: 0.315739 |  Acc: 100.000% (25600/25600)
[47,   300] loss: 0.473674 |  Acc: 100.000% (38400/38400)
Total loss: 0.619973

Epoch: 47
[48,   100] loss: 0.163760 |  Acc: 100.000% (12800/12800)
[48,   200] loss: 0.322436 |  Acc: 100.000% (25600/25600)
[48,   300] loss: 0.487261 |  Acc: 100.000% (38400/38400)
Total loss: 0.619886

Epoch: 48
[49,   100] loss: 0.160341 |  Acc: 100.000% (12800/12800)
[49,   200] loss: 0.328375 |  Acc: 100.000% (25600/25600)
[49,   300] loss: 0.497179 |  Acc: 100.000% (38400/38400)
Total loss: 0.643087

Epoch: 49
[50,   100] loss: 0.156791 |  Acc: 100.000% (12800/12800)
[50,   200] loss: 0.309782 |  Acc: 100.000% (25600/25600)
[50,   300] loss: 0.466129 |  Acc: 100.000% (38400/38400)
Total loss: 0.606150
Epoch    51: reducing learning rate of group 0 to 1.0000e-04.
</code></pre>
<h3 id="save-model"><a href="#save-model" class="headerlink" title="save model"></a>save model</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">save_model = <span class="hljs-literal">True</span><br><span class="hljs-keyword">if</span> save_model:<br>    state = &#123;<br>        <span class="hljs-string">&#x27;net&#x27;</span>: net.state_dict(),<br>        <span class="hljs-string">&#x27;epoch&#x27;</span>: epoch,<br>    &#125;<br>    os.makedirs(<span class="hljs-string">&#x27;checkpoint&#x27;</span>, exist_ok=<span class="hljs-literal">True</span>)<br>    torch.save(state, <span class="hljs-string">&#x27;./checkpoint/res18.ckpt&#x27;</span>)<br></code></pre></td></tr></table></figure>

<h3 id="evaluate"><a href="#evaluate" class="headerlink" title="evaluate"></a>evaluate</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python">dataiter = <span class="hljs-built_in">iter</span>(test_loader)<br>images, labels = dataiter.<span class="hljs-built_in">next</span>()<br>images = images[:<span class="hljs-number">4</span>]<br>labels = labels[:<span class="hljs-number">4</span>]<br><span class="hljs-comment"># print images</span><br>imshow(torchvision.utils.make_grid(images))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;GroundTruth: &#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>.join(<span class="hljs-string">&#x27;%5s&#x27;</span> % classes[labels[j]] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)))<br><br>outputs = net(images.to(device))<br>_, predicted = torch.<span class="hljs-built_in">max</span>(outputs.cpu(), <span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Predicted: &#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>.join(<span class="hljs-string">&#x27;%5s&#x27;</span> % classes[predicted[j]]<br>                              <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)))<br>correct = <span class="hljs-number">0</span><br>total = <span class="hljs-number">0</span><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_loader:<br>        images, labels = data<br>        images, labels = images.to(device), labels.to(device)<br>        outputs = net(images)<br>        _, predicted = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)<br>        total += labels.size(<span class="hljs-number">0</span>)<br>        correct += (predicted == labels).<span class="hljs-built_in">sum</span>().item()<br><br><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Accuracy of the network on the 10000 test images: %d %%&#x27;</span> % (<br>    <span class="hljs-number">100</span> * correct / total))<br><br><br><br>class_correct = <span class="hljs-built_in">list</span>(<span class="hljs-number">0.</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>))<br>class_total = <span class="hljs-built_in">list</span>(<span class="hljs-number">0.</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>))<br><span class="hljs-keyword">with</span> torch.no_grad():<br>    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_loader:<br>        images, labels = data<br>        images, labels = images.to(device), labels.to(device)<br>        outputs = net(images)<br>        _, predicted = torch.<span class="hljs-built_in">max</span>(outputs, <span class="hljs-number">1</span>)<br>        c = (predicted == labels).squeeze()<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>):<br>            label = labels[i]<br>            class_correct[label] += c[i].item()<br>            class_total[label] += <span class="hljs-number">1</span><br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Accuracy of %5s : %2d %%&#x27;</span> % (<br>        classes[i], <span class="hljs-number">100</span> * class_correct[i] / class_total[i]))<br></code></pre></td></tr></table></figure>

<p><img src="https://madao33-static.oss-cn-hangzhou.aliyuncs.com/madao33blog/post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/resnet/ResNet_22_0.png" srcset="/img/loading.gif" lazyload></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs plain">GroundTruth:    cat  ship  ship plane<br>Predicted:    cat  ship   car plane<br>Accuracy of the network on the 10000 test images: 90 %<br>Accuracy of plane : 90 %<br>Accuracy of   car : 100 %<br>Accuracy of  bird : 81 %<br>Accuracy of   cat : 72 %<br>Accuracy of  deer : 89 %<br>Accuracy of   dog : 87 %<br>Accuracy of  frog : 94 %<br>Accuracy of horse : 93 %<br>Accuracy of  ship : 95 %<br>Accuracy of truck : 96 %<br></code></pre></td></tr></table></figure>



<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id="ref-1"></div>

<ul>
<li>[1] <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/31852747/">知乎文章：你必须要知道CNN模型：ResNet</a></li>
</ul>
<div id="ref-2"></div>

<ul>
<li>[2] <a target="_blank" rel="noopener" href="http://kaiminghe.com/">何凯明个人主页</a></li>
</ul>
<div id="ref-3"></div>

<ul>
<li>[3] <a target="_blank" rel="noopener" href="https://blog.csdn.net/c2250645962/article/details/102838830">csdn博客：网络退化、过拟合、梯度消散&#x2F;爆炸</a></li>
</ul>
<div id="ref-4"></div>

<ul>
<li>[4] <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1512.03385.pdf">He K ,  Zhang X ,  Ren S , et al. Deep Residual Learning for Image Recognition[J]. 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.</a></li>
</ul>
<div id="ref-5"></div>

<ul>
<li>[5] <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/106764370">知乎文章：CVPR2016:ResNet 从根本上解决深度网络退化问题</a></li>
</ul>
<div id="ref-6"></div>

<ul>
<li>[6] <a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">Krizhevsky A , Sutskever I , Hinton G . ImageNet Classification with Deep Convolutional Neural Networks[J]. Advances in neural information processing systems, 2012, 25(2).</a></li>
</ul>
<div id="ref-7"></div>

<ul>
<li>[7] <a target="_blank" rel="noopener" href="https://github.com/Bingmang/pytorch-cifar10-notebook">Bingmang&#x2F;pytorch-cifar10-notebook</a></li>
</ul>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="category-chain-item">深度学习</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/ResNet/">#ResNet</a>
      
        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">#深度学习</a>
      
        <a href="/tags/cnn/">#cnn</a>
      
        <a href="/tags/python/">#python</a>
      
        <a href="/tags/pytorch/">#pytorch</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>ResNet学习笔记及代码实现</div>
      <div>http://example.com/2021/08/06/深度学习/ResNet网络简述及代码实现/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>madao33</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>August 6, 2021</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/07/14/%E7%AC%94%E8%AF%95%E8%AE%B0%E5%BD%95/%E8%94%9A%E6%9D%A5%E6%8F%90%E5%89%8D%E6%89%B97-13/" title="蔚来提前批7-13">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">蔚来提前批7-13</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.1/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
